{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSOC as a Convoultional Layer\n",
    "\n",
    "This work is based on papers by Dr. Gabriel Ferrer from Hendrix College. I will explore the practicality of using Bounded Self-Organizing Clusters (BSOC) as a way to create the first convoultional in a convoultional network. I will be using Pytorch as a baseline in this notebook.\n",
    "\n",
    "## Data:\n",
    "The data comes from pictures taken on a Galaxy S8 at 1280x720px.\n",
    "### 7/9/2018\n",
    "Room: 10 Pictures <br/>\n",
    "Kitchen: 10 Pictures\n",
    "\n",
    "## 1: Defining Our Heaps and BSOCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import heapq as hq\n",
    "\n",
    "## Let's write a wrapper around heapq to help keep us sane.\n",
    "## this heap needs to let us remove an arbitrary amount of edges\n",
    "\n",
    "class Heap():\n",
    "    def __init__(self):\n",
    "        self.list = []\n",
    "    def add(self, item, priority=0):\n",
    "        hq.heappush(self.list, (priority, item))\n",
    "    def add_many(self, entries_list, entries_priorities):\n",
    "        self.list += [li for li in zip(entries_priorities, entries)]\n",
    "        hq.heapify(self.list)\n",
    "    def pop(self):\n",
    "        return hq.heappop(self.list)\n",
    "    def filter_f(self, filter_func):\n",
    "        self.list = list(filter(filter_func, self.list))\n",
    "        hq.heapify(self.list)\n",
    "    def remove_many(self, entries):\n",
    "        set_check = set(entries)\n",
    "        self.list = [(p,e) for p,e in self.list if e not in set_check]\n",
    "        hq.heapify(self.list)\n",
    "        ## we do this because it is faster to create a new list rather than modify a ton of items in a list\n",
    "        ## Todo, check if this is faster than a for loop to remove each item from a list.\n",
    "    def __remove_1(self, entry):\n",
    "        i_to_remove = -1;\n",
    "        for i in range(len(self.list)):\n",
    "            p,e = self.list[i]\n",
    "            if e == entry:\n",
    "                i_to_remove = i\n",
    "        if i_to_remove == -1:\n",
    "            raise ValueError(\"Could not find entry in heap\")\n",
    "        del self.list[i_to_remove]\n",
    "    \n",
    "    def remove_any_instance_of(self, i):\n",
    "        self.list = [(p,e) for (p,e) in self.list if (e.a != i and e.b != i)]\n",
    "        hq.heapify(self.list)\n",
    "    def remove(self, entry):\n",
    "        self.__remove_1(entry)\n",
    "        hq.heapify(self.list)\n",
    "    def remove_many_inplace(self, entries):\n",
    "        for e in entries:\n",
    "            self.__remove_1(e)\n",
    "        \n",
    "    \n",
    "        \n",
    "## Let's also just name our edges\n",
    "class Edge():\n",
    "    def __init__(self, a, b, weight):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.weight = weight\n",
    "    def __eq__(self, other):\n",
    "#         print(type(self.a))\n",
    "#         print(type(self.b))\n",
    "        return other.contains(self.a) and other.contains(self.b) and other.weight == self.weight\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.weight < other.weight\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.weight <= other.weight\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        return self.weight > other.weight\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return self.weight >= other.weight\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.a.ID) + \" \" + str(self.b.ID) + \" \" + str(self.weight)\n",
    "    ## checks if a or b is c\n",
    "    def contains(self, c):\n",
    "        t1 = self.a == c\n",
    "        t2 = self.b == c\n",
    "        return t1 or t2\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining BSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSOC_Image_Node():\n",
    "    def __init__(self, node_height, node_width, node_channels, ID = -1,  merge_count = 1, array=None):\n",
    "        self.height = node_height\n",
    "        self.width = node_width\n",
    "        self.channels = node_channels\n",
    "        self.ID = ID\n",
    "        \n",
    "        if array is None:\n",
    "            self.array = np.zeros(shape=(node_height, node_width, node_channels))\n",
    "        else :\n",
    "            self.array = array\n",
    "        self.merge_count = merge_count\n",
    "    \n",
    "    ## Returns a new node of this node and the other node merged together\n",
    "    ## merge_f(node1, node2) returns new node. \n",
    "    def merge(self, other_node, new_ID, merge_func = None):\n",
    "        if merge_func == None:\n",
    "            ## default merge\n",
    "            newCount = self.merge_count + other_node.merge_count\n",
    "            a1 = self.array\n",
    "            a2 = other_node.array\n",
    "            r1 = self.merge_count / newCount\n",
    "            r2 = other_node.merge_count / newCount\n",
    "            a3 = (a1 * r1) + (a2 * r2)\n",
    "            return BSOC_Image_Node(self.height, self.width, self.channels, ID=new_ID, merge_count = newCount, array=a3)\n",
    "        return merge_func(self, other_node)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return other.ID == self.ID\n",
    "#         return np.array_equal(self.array, other.array) and self.merge_count == other.merge_count\n",
    "    def __repr__(self):\n",
    "        return self.array.__repr__()\n",
    "        \n",
    "    def calculate_distance(self, other):\n",
    "        return (self.merge_count + other.merge_count) * np.sum(np.absolute(self.array - other.array))\n",
    "        \n",
    "        \n",
    "        \n",
    "class BSOC():\n",
    "    def __init__(self, nodes_count, node_channels=1):\n",
    "        self.total_nodes = nodes_count\n",
    "        self.node_channels = node_channels\n",
    "        self.node_list = []\n",
    "        self.pq = Heap()\n",
    "        self.generator = self.__default_generator()\n",
    "        \n",
    "    def __default_generator(self):\n",
    "        i = 0\n",
    "        while True:\n",
    "            yield i\n",
    "            i += 1\n",
    "    def next_ID(self):\n",
    "        return next(self.generator)\n",
    "    ## if we're below the node threshold, then place the pixel array into the numpy list, \n",
    "    def add_node(self, pixel_arr):\n",
    "        node = BSOC_Image_Node(pixel_arr.shape[0], pixel_arr.shape[1], pixel_arr.shape[2], ID=self.next_ID(), array=pixel_arr)\n",
    "        ## Add the node to the priority queue. \n",
    "        self.add_node_and_edges(node)\n",
    "        if len(self.node_list) > self.total_nodes:\n",
    "            weight, e = self.pq.pop()\n",
    "            self.node_list = [x for x in self.node_list if x not in (e.a, e.b) ] ## deletes a and b from the list\n",
    "            self.pq.remove_any_instance_of(e.a)\n",
    "            self.pq.remove_any_instance_of(e.b)\n",
    "            self.__merge(e.a, e.b)\n",
    "\n",
    "            \n",
    "                    \n",
    "    def add_node_and_edges(self, node):\n",
    "        for n in self.node_list:\n",
    "            e = Edge(node, n, weight=n.calculate_distance(node))\n",
    "            self.pq.add(e, e.weight)\n",
    "        self.node_list.append(node)\n",
    "\n",
    "    ## merges nodes a and b and adds their respective edges to the priority queue\n",
    "    ## merge_func = function to merge together the nodes at the indeces\n",
    "    def __merge(self, a, b, merge_func=None):\n",
    "        new_node = a.merge(b, self.next_ID(), merge_func)\n",
    "        self.add_node_and_edges(new_node)\n",
    "\n",
    "        \n",
    "    ## Only works on raw images, if converted to tensors or loaded from pytorch default libraries, it won't show\n",
    "    def print_bsoc(self, ncols=-1, nrows=1):\n",
    "        if ncols * nrows < len(self.node_list):\n",
    "            ncols = len(self.node_list)\n",
    "        fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(20, 10))\n",
    "        print(len(self.node_list))\n",
    "            \n",
    "        for i in range(len(self.node_list)):\n",
    "            a = axeslist.ravel()[i]\n",
    "            a.imshow(self.node_list[i].array.astype(np.int64))\n",
    "            a.get_xaxis().set_visible(False)\n",
    "            a.get_yaxis().set_visible(False)\n",
    "            a.set_title('Merged {}x {}'.format(self.node_list[i].merge_count, self.node_list[i].ID))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSOC Test\n",
    "\n",
    "We need to verify that we correctly implemented BSOC, so let's see the output of combining a few images together\n",
    "\n",
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get out data files\n",
    "import os\n",
    "\n",
    "## Creating a base class for our dataset\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class simpleImageDataset(Dataset):\n",
    "    \"\"\" Loads images, it assumes that the folder in which the file is stored is the label \"\"\"\n",
    "    \n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.label_to_ind_dict = {}\n",
    "        self.ind_to_label = {}\n",
    "        self.labels = []\n",
    "        self.file_paths = []\n",
    "        self.transform = transform\n",
    "        self.label_count = 0\n",
    "        for dirpath, dirname, filenames in os.walk(directory):\n",
    "            for file in filenames:\n",
    "                label = dirpath.split(os.sep)[-1]\n",
    "                if label not in self.label_to_ind_dict:\n",
    "                    self.label_to_ind_dict[label] = self.label_count\n",
    "                    self.ind_to_label[self.label_count] = label\n",
    "                    self.label_count += 1\n",
    "                self.labels.append(dirpath.split(os.sep)[-1])\n",
    "                self.file_paths.append(os.path.join(dirpath, file))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        sample = {'image':image}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = {'image': self.transform(image)}\n",
    "        return sample\n",
    "    def label_for(self, idx):\n",
    "        return self.labels[idx]\n",
    "    def label_tensor(self, idx):\n",
    "        return torch.Tensor([self.label_to_ind_dict[self.label_for(idx)], self.label_count])\n",
    "\n",
    "## Viewing our Data\n",
    "room_dataset = simpleImageDataset(\"./Data\", transform=transforms.Compose([transforms.Resize((72,128))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "## Generates kernels_count kernels of kernel_size from dataset \n",
    "def generate_kernels(kernels_count, kernel_size, dataset):\n",
    "    start_time = time.time() * 1000\n",
    "    bsoc = BSOC(nodes_count=kernels_count)\n",
    "    offset = (kernel_size // 2) * 2\n",
    "    for i,data in enumerate(dataset, 0):\n",
    "#     for i in range(1):\n",
    "        image = data[0].numpy()\n",
    "        ## Iterate through the image\n",
    "        for r in range(len(image[1]) - offset):\n",
    "            r_stop = r + kernel_size\n",
    "            for c in range(len(image[2]) - offset):\n",
    "                bsoc.add_node(image[:,r:r_stop, c:c+kernel_size])\n",
    "    print(\"Total time in milli: \" + str(time.time()*1000 - start_time))\n",
    "    return bsoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BSOC using Test Data\n",
    "\n",
    "We make sure BSOC appears to cluster correctly using the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[37, 40, 37, 36, 35, 33, 39, 38, 42, 63]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = simpleImageDataset(\"./test_data/\")\n",
    "bsoc = BSOC(nodes_count=10)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    bsoc.add_node(np.array(test_dataset[i]['image']))\n",
    "bsoc.print_bsoc(nrows=2, ncols=5)\n",
    "[x.merge_count for x in bsoc.node_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it reasonably works, now let's test it on our room data by loading the data using the built in functions and resizing the images to 72x128px images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_dataset2 = torchvision.datasets.ImageFolder(root=\"./Data\",transform=transforms.Compose([transforms.Resize((72,128)),\n",
    "                                                                                    transforms.ToTensor()]))\n",
    "\n",
    "roomLoader = torch.utils.data.DataLoader(room_dataset2,batch_size=20,\n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time in milli: 35476.592529296875\n"
     ]
    }
   ],
   "source": [
    "bsoc = generate_kernels(10, 5, room_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels = [x.array for x in bsoc.node_list]\n",
    "kernels = torch.from_numpy(np.array(kernels))\n",
    "kernels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import queue\n",
    "\n",
    "\n",
    "\n",
    "class BSOCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BSOCNet, self).__init__()\n",
    "        ## These dimensions are because there are 10 kernels, we lose 4 on the other dimensions (from 72, 128) \n",
    "        ## Because we are not padding, we are losing 2 on each side of the image. \n",
    "        self.fc = nn.Linear(10 * 68 * 124, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, kernels, padding=0, stride=1)\n",
    "        x = x.view(-1, 10*68*124)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "net = BSOCNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our network defined (with the Convolutional network as a template, not benchmark). Let's see if we train using our 20 images repeated 40 times if our network can learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "    for i, data in enumerate(roomLoader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "#         running_loss += loss.item()\n",
    "#         print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3369.1519 -3372.0742]\n",
      "Kitchen\n",
      "[ 5926.7954 -5920.6816]\n",
      "Kitchen\n",
      "[ 5474.402  -5466.0522]\n",
      "Kitchen\n",
      "[ 4416.003  -4411.0635]\n",
      "Kitchen\n",
      "[ 7963.2197 -7958.658 ]\n",
      "Kitchen\n",
      "[-876.7017   886.81067]\n",
      "Room\n",
      "[ 5500.0884 -5493.6187]\n",
      "Kitchen\n",
      "[ 1019.215  -1016.8297]\n",
      "Kitchen\n",
      "[ 12823.803 -12815.991]\n",
      "Kitchen\n",
      "[ 5476.551 -5467.156]\n",
      "Kitchen\n",
      "[-6433.575   6441.9175]\n",
      "Room\n",
      "[-2642.958  2646.028]\n",
      "Room\n",
      "[ 1753.0742 -1752.0314]\n",
      "Kitchen\n",
      "[-7812.5522  7818.076 ]\n",
      "Room\n",
      "[-5951.856  5960.973]\n",
      "Room\n",
      "[-10553.076  10557.705]\n",
      "Room\n",
      "[-13388.41   13393.963]\n",
      "Room\n",
      "[-14854.46   14854.911]\n",
      "Room\n",
      "[-20619.225  20622.531]\n",
      "Room\n",
      "[-17260.115  17257.422]\n",
      "Room\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Kitchen', 'Room']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,data in enumerate(roomLoader, 0):\n",
    "    inputs, labels = data\n",
    "    output = net(inputs)\n",
    "    for j in output.data:\n",
    "        p = j.numpy()\n",
    "        ind = np.where(p == max(p))[0][0]\n",
    "        print(p)\n",
    "        print(room_dataset2.classes[ind])\n",
    "room_dataset2.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is done by taking the maximum value of the outputs. therefore, we see that in our inorder data, we have classified the first 10 images as Kitchen, and 9 (or 10, depending on trial and luck) out of 10 of the remainig images as Room. Of course, we expect good results because of the smalll sample size and the fact that we are testing on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.fc1 = nn.Linear(10 * 68 * 124, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(-1, 10 * 68 * 124)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "net2 = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "    for i, data in enumerate(roomLoader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1426086  -0.90841144]\n",
      "Kitchen\n",
      "[ 1.1698337 -1.0974243]\n",
      "Kitchen\n",
      "[ 1.2155966 -0.9470705]\n",
      "Kitchen\n",
      "[0.14495961 0.2881697 ]\n",
      "Room\n",
      "[ 1.4272242 -1.061355 ]\n",
      "Kitchen\n",
      "[0.33529133 0.03132847]\n",
      "Kitchen\n",
      "[ 0.66311187 -0.48263606]\n",
      "Kitchen\n",
      "[ 0.43383834 -0.23321143]\n",
      "Kitchen\n",
      "[ 1.7784904 -1.333925 ]\n",
      "Kitchen\n",
      "[ 1.2260749  -0.84163505]\n",
      "Kitchen\n",
      "[-0.7140519  1.00108  ]\n",
      "Room\n",
      "[-0.08620625  0.35013425]\n",
      "Room\n",
      "[ 0.6629934 -0.2916848]\n",
      "Kitchen\n",
      "[-1.3223685  1.6481109]\n",
      "Room\n",
      "[-0.8564104  1.1311259]\n",
      "Room\n",
      "[-1.6083596  1.8339676]\n",
      "Room\n",
      "[-1.7706617  2.0158775]\n",
      "Room\n",
      "[-1.7566941  2.1005387]\n",
      "Room\n",
      "[-1.8811066  2.0436385]\n",
      "Room\n",
      "[-1.6791734  1.855024 ]\n",
      "Room\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Kitchen', 'Room']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,data in enumerate(roomLoader, 0):\n",
    "    inputs, labels = data\n",
    "    output = net2(inputs)\n",
    "    for j in output.data:\n",
    "        p = j.numpy()\n",
    "        ind = np.where(p == max(p))[0][0]\n",
    "        print(p)\n",
    "        print(room_dataset2.classes[ind])\n",
    "room_dataset2.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a neat result because we see that our Convoultional network falsely classifies a lot more than our fixed one. We know this because we expect the first 10 to be Kitchen and the last 10 to be Room since this is how we trained it. I was expecting equal performance to the BSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_rand = torch.randn(10,3,5,5)\n",
    "class ConvNetFixedKernels(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNetFixedKernels, self).__init__()\n",
    "        self.fc = nn.Linear(10 * 68 * 124, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, kernels_rand, padding=0, stride=1)\n",
    "        x = x.view(-1, 10 * 68 * 124)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "net3 = ConvNetFixedKernels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net3.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "    for i, data in enumerate(roomLoader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net3(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.574949 -11.713362]\n",
      "Kitchen\n",
      "[ 39.927414 -43.628204]\n",
      "Kitchen\n",
      "[ 20.00264  -24.587425]\n",
      "Kitchen\n",
      "[ 54.078552 -57.163506]\n",
      "Kitchen\n",
      "[  97.59509 -103.39204]\n",
      "Kitchen\n",
      "[-38.226208  32.126045]\n",
      "Room\n",
      "[ 70.26821  -74.150345]\n",
      "Kitchen\n",
      "[ 11.590749 -14.532576]\n",
      "Kitchen\n",
      "[ 174.35808 -179.68974]\n",
      "Kitchen\n",
      "[ 73.182945 -77.34572 ]\n",
      "Kitchen\n",
      "[-105.09409  100.46385]\n",
      "Room\n",
      "[-80.87271  77.49111]\n",
      "Room\n",
      "[-86.66643  82.23345]\n",
      "Room\n",
      "[-179.72525  174.69305]\n",
      "Room\n",
      "[-127.36094  121.67215]\n",
      "Room\n",
      "[-210.19641  205.38268]\n",
      "Room\n",
      "[-261.60257  255.47517]\n",
      "Room\n",
      "[-254.55688  251.16011]\n",
      "Room\n",
      "[-292.3463  290.0814]\n",
      "Room\n",
      "[-287.8599   284.37006]\n",
      "Room\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(roomLoader, 0):\n",
    "    inputs, labels = data\n",
    "    output = net3(inputs)\n",
    "    for j in output.data:\n",
    "        p = j.numpy()\n",
    "        ind = np.where(p == max(p))[0][0]\n",
    "        print(p)\n",
    "        print(room_dataset2.classes[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at this result, we see that our randomly made fixed kernels network are a lot worse than our BSOCs! This tells us that pre-seeding a convoultional network will give us faster training (in our specific case of 20 images repeated 40 times using the specific images we have here)! This gives promising results and could potentially mean that we can more quickly train neural nets simply passing our images through a BSOC. There are obviously questions and future work available: \n",
    "* Will this still work when we increase the train and test data?\n",
    "* What is performance when not testing on training data?\n",
    "* Will dynamically changing BSOCs instead of statically generated before hand be better?\n",
    "* To what extent will altering the number of BSOC nodes and kernels change performance?\n",
    "\n",
    "I did not create bsocs which train as we go because of the nature of my implementation of BSOC. Because I remove both of the closest nodes and re add them to the node list, the order of nodes shifts all the time.\n",
    "\n",
    "# Questions from Dr. Ferrer\n",
    "* How do people define convolutional layers initially besides random. \n",
    "* <s>ConvNet with fixed kernels and without (no back propagation)</s>\n",
    "* <s>ConvNet without fixed kernels (Normal)</s>\n",
    "* <s>BSOCNet with Fixed kernels (Hypothesis)</s>\n",
    "* BSOCNet with without fixed kernels. \n",
    "* how are the convolutional network weights back propagated?\n",
    "* <s>Generate test images with squares in them to see if bsoc works correctly</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
